---

## Storage mode. Either READ_WRITE or READ_ONLY
## When configured in READ_ONLY mode, it won't allow to make any modifications to the storage.
## If undefined, the value is "READ_WRITE"
mode: READ_WRITE

## CellBase client configuration, this is used mainly when annotating variants
## This can be set up using maven profiles in your .m2/settings.xml
cellbase:
  ## URL host to annotate variants, for example: https://uk.ws.zettagenomics.com/cellbase/
  url: "${OPENCGA.CELLBASE.REST.HOST}"
  version: "${OPENCGA.CELLBASE.VERSION}"
  dataRelease: "2"

## Storage Query Server configuration. When CLI is launched in 'server' mode a RESTful web server
## is launched in the specified port.
server:
  rest:
    port: ${OPENCGA.SERVER.REST.PORT}
    logFile: null
  grpc:
    port: ${OPENCGA.SERVER.GRPC.PORT}
    logFile: null

## Solr Search Configuration
search:
  # List of hosts pointing either to the Solr nodes directly using a complete URL or to the zookeper nodes with HOST:PORT
  #    Example for Solr connection:       http://opencga-solr-01.zone:8983/solr
  #    Example for Zookeeper connection:  opencga-zookeeper-01:2181               <-- Recommended for replicated installations
  hosts:
  - ${OPENCGA.STORAGE.SEARCH.HOST}
  configSet: "${OPENCGA.STORAGE.SEARCH.CONFIG_SET}"
  mode: "cloud"
  timeout: ${OPENCGA.STORAGE.SEARCH.TIMEOUT}
  insertBatchSize: 5000

## Clinical database for indexing the pathogenic variants reported.
clinical:
  # List of hosts pointing either to the Solr nodes directly using a complete URL or to the zookeper nodes with HOST:PORT
  #    Example for Solr connection:       http://opencga-solr-01.zone:8983/solr
  #    Example for Zookeeper connection:  opencga-zookeeper-01:2181               <-- Recommended for replicated installations
  hosts:
  - ${OPENCGA.STORAGE.CLINICAL.HOST}    # URL containing host and port, e.g. http://localhost:8983/solr/
  mode: "cloud"
  manager: ${OPENCGA.STORAGE.CLINICAL.MANAGER}
  timeout: ${OPENCGA.STORAGE.CLINICAL.TIMEOUT}
  insertBatchSize: 1000

## Recessive Gene Analysis database.
rga:
  # List of hosts pointing either to the Solr nodes directly using a complete URL or to the zookeper nodes with HOST:PORT
  #    Example for Solr connection:       http://opencga-solr-01.zone:8983/solr
  #    Example for Zookeeper connection:  opencga-zookeeper-01:2181               <-- Recommended for replicated installations
  hosts:
    - ${OPENCGA.STORAGE.RGA.HOST}    # URL containing host and port, e.g. http://localhost:8983/solr/
  configSet: "${OPENCGA.STORAGE.RGA.CONFIG_SET}"
  mode: "cloud"
  timeout: ${OPENCGA.STORAGE.RGA.TIMEOUT}
  insertBatchSize: 1000

benchmark:
  numRepetitions: 20           # Number of query repetitions
  concurrency: 5               # Number of concurrent threads
  delay: 100                   # Delay between queries
  connectionType: REST         # Select between REST or DIRECT.
  mode: FIXED                  # Select between FIXED or RANDOM
  databaseName: "opencga"
  rest: "http://localhost:8080/${opencga.war.name}"

io:
  connectors:
#    azure:
#      class: "org.opencb.opencga.storage.core.io.managers.AzureBlobStorageIOConnector"
#      options:
#        accountName: "<accountName>"
#        accountKey: "<accountKey>"

alignment:
  bigWigWindowsSize: 1

variant:
  defaultEngine: "${OPENCGA.STORAGE.DEFAULT_ENGINE}"
  options:
    transform.batchSize: 200
    transform.numThreads: 4
    transform.format: "avro"
    transform.compression: "gzip"
    transform.failOnMalformed: true

    normalization.skip: false         # Skip normalization
    normalization.referenceGenome: "" # Reference genome localization for improved normalization
    normalization.extensions: []      # Enable VariantNormalizerExtensions
    #  - "VAF" # Compute EXT_VAF for each sample. Variant Allele Fraction (VAF), several variant callers supported

    load.batchSize: 100
    load.numThreads: 6

    stats.defaultGenotype: "0/0"    # Default genotype to be used for calculating stats.
    stats.multiAllelic: false       # Include secondary alternates in the variant stats calculation
    stats.calculate.batchSize: 100
    stats.calculate.numThreads: 4
    stats.load.batchSize: 100
    stats.load.numThreads: 4


    annotation.batchSize: 100
    annotation.numThreads: 8
    annotation.checkpointSize: 5000000
    annotation.timeout: 600000 # millis
    annotation.load.batchSize: 100
    annotation.load.numThreads: 4
    annotation.file.format: "json"
    annotator: "cellbase"
    #annotator.class: #Allows to inject custom annotators
    annotator.cellbase.exclude: "expression"
    annotator.cellbase.useCache: true
    annotator.cellbase.impreciseVariants: true          # Imprecise variants supported by cellbase
    annotator.cellbase.starAlternate: false             # Variants with stat "*" alternate supported by cellbase
    #annotator.cellbase.variantLengthThreshold:         # Variants length threshold. By default, unlimited

    query.timeout.default: 10000 #(ms) Default timeout for DBAdaptor operations. Only used if none is provided.
    query.timeout.max: 30000     #(ms) Max allowed timeout for DBAdaptor operations.
    query.limit.default: 1000              # Default limit in GET operations. To be used only if not defined.
    query.limit.max: 5000                  # Maximum limit value in GET operations. If tried to be exceeded, the query will fail.
    query.sample.limit.default: 100        # Default sampleLimit in GET operations. To be used only if not defined.
    query.sample.limit.max: 1000           # Maximum sampleLimit value in GET operations. If tried to be exceeded, the query will fail.

    search.intersect.active: true           # Allow intersect queries with the SearchEngine (Solr)
    search.intersect.always: false          # Force intersect queries
    search.intersect.params.threshold: 3    # Minimum number of QueryParams in the query to intersect

  ## The following section defines all available storage engine plugins installed
  engines:
    ## Hadoop Storage Engine
    - id: "hadoop"
      engine: "org.opencb.opencga.storage.hadoop.variant.HadoopVariantStorageEngine"
      database:
        # PENDING Kerberos authentication support:
        # See https://github.com/opencb/opencga/issues/1292
        user: "${OPENCGA.STORAGE.HADOOP.VARIANT.DB.USER}"
        password: "${OPENCGA.STORAGE.HADOOP.VARIANT.DB.PASSWORD}"
      options:
        storage.hadoop.hbase.namespace: "${OPENCGA.STORAGE.HADOOP.VARIANT.HBASE.NAMESPACE}"
        storage.hadoop.archive.table.preSplit.splitsPerBatch: 500
        storage.hadoop.archive.table.compression: "gz"               # Allowed values: none, snappy, gz
        storage.hadoop.archive.table.chunkSize: 1000
        storage.hadoop.archive.table.fileBatchSize: 1000
        storage.hadoop.variant.table.preSplit.numSplits: 500
        storage.hadoop.variant.table.compression: "snappy"           # Allowed values: none, snappy, gz
        storage.hadoop.sampleIndex.table.preSplit.samplesPerSplit: 15
        storage.hadoop.sampleIndex.table.compression: "snappy"       # Allowed values: none, snappy, gz
        storage.hadoop.sampleIndex.build.maxSamplesPerMR: 2000
        storage.hadoop.sampleIndex.annotation.maxSamplesPerMR: 2000
        storage.hadoop.annotationIndex.table.compression: "snappy"   # Allowed values: none, snappy, gz
        storage.hadoop.pendingAnnotation.table.compression: "snappy" # Allowed values: none, snappy, gz

        # Batch size for querying phoenix
        storage.hadoop.phoenix.fetchSize: -1

        # Hadoop executable file. Used to lunch MapReduce applications
        storage.hadoop.bin: "hadoop"

        ## If undefined, it will be generated based on the build version.
        #storage.hadoop.mr.jarWithDependencies: "opencga-storage-hadoop-core-${project.parent.version}-jar-with-dependencies.jar"

        # Define the MapReduce job executor.
        storage.hadoop.mr.executor: "system"  # Either "system" or "ssh".

        # Use external hadoop installation. ssh to a hadoop edge node
        storage.hadoop.mr.executor.ssh.host: ""               # Hadoop edge node host name
        storage.hadoop.mr.executor.ssh.user: ""               # Hadoop edge node user name
       #storage.hadoop.mr.executor.ssh.key: "~/.ssh/id_rsa"   # Hadoop edge node ssh-key file
        storage.hadoop.mr.executor.ssh.password: ""           # Hadoop edge node password. Only if ssh-key is not present. Requires sshpass to run
        storage.hadoop.mr.executor.ssh.remoteOpenCgaHome:     # Remote opencga home location. Only if different than local location.

        # Increase the ScannerTimeoutPeriod from 60000 (1min) to 300000 (5min) to avoid ScannerTimeoutExceptions
        # See opencb/opencga#352 for more info.
        storage.hadoop.mr.scanner.timeout: 300000

        mapreduce.map.memory.mb: 2048
        DeleteHBaseColumnDriver:
          storage.hadoop.write.mappers.limit.factor: 4
        DiscoverPendingVariantsDriver:
          mapreduce.map.memory.mb: 750
        VariantStatsDriver:
          mapreduce.map.memory.mb: 2048
        SampleIndexDriver:
          mapreduce.map.memory.mb: 4096
          max-columns-per-scan: 8000
        SampleIndexAnnotationLoaderDriver:
          mapreduce.map.memory.mb: 4096
        VariantMigration200Driver:
          mapreduce.map.memory.mb: 1024


## PENDING
## Cache Configuration
cache:
  host: ${OPENCGA.STORAGE.CACHE.HOST}
  active: true
  serialization: "json"
  slowThreshold: 50
  allowedTypes: "aln,var"
  maxResultSize: 5000
  password: ""