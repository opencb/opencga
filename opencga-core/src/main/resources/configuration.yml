---
logLevel: "INFO"
logDir: ${OPENCGA.INSTALLATION.DIR}/logs

databasePrefix: ${OPENCGA.DB.PREFIX}
workspace: ${OPENCGA.USER.WORKSPACE}
jobDir: ${OPENCGA.USER.WORKSPACE}/jobs

# Maximum number of login attempts before banning a user account
account:
  maxLoginAttempts: ${OPENCGA.ACCOUNT.MAX_LOGIN_ATTEMPTS}
  passwordExpirationDays: 90

panel:
  host: "http://resources.opencb.org/opencb/opencga/disease-panels"

## Configuration for Catalog databases
catalog:
  database: # MongoDB database credentials
    hosts:
      - ${OPENCGA.CATALOG.DB.HOSTS}
    user: ${OPENCGA.CATALOG.DB.USER}
    password: ${OPENCGA.CATALOG.DB.PASSWORD}
    options:
      authenticationDatabase: ${OPENCGA.CATALOG.DB.AUTHENTICATION_DATABASE}
      connectionsPerHost: ${OPENCGA.CATALOG.DB.CONNECTIONS_PER_HOST}

server:
  rest:
    port: ${OPENCGA.SERVER.REST.PORT}
    httpConfiguration:
      # The size in bytes of the output buffer used to aggregate HTTP output
      outputBufferSize: 32768
      # The maximum size in bytes for HTTP output to be aggregated
      outputAggregationSize: 8192
      # The maximum allowed size in bytes for a HTTP request header
      requestHeaderSize: 8192
      # The maximum allowed size in bytes for a HTTP response header
      responseHeaderSize: 8192
      # The maximum allowed size in bytes for a HTTP header field cache
      headerCacheSize: 4096

  grpc:
    port: ${OPENCGA.SERVER.GRPC.PORT}

audit:
  manager: ""             # Java manager of the audit implementation to be used to audit. If empty, catalog database will be used.
  maxDocuments: 20000000  # Maximum number of documents that will be created in the audit collection.
  maxSize: 100            # Maximum size that the audit collection will have in Gigabytes (GB).

monitor:
  daysToRemove: 30
  executionDaemonInterval: 4000 # number of milliseconds between checks
  fileDaemonInterval: 8000      # number of milliseconds between checks
  port: ${OPENCGA.MONITOR.PORT}

healthCheck:
  interval: 30 # seconds to get actual healthCheck than cache

#execution:
#  mode: ${OPENCGA.EXECUTION.MODE}
#  maxConcurrentIndexJobs : 1 # only applies to local executor
#  defaultQueue: ""
#  availableQueues: ""
#  toolsPerQueue: {}
#  options:


analysis:
  # List of packages where to find analysis tools
  packages:
    - "org.opencb.opencga"
  # Scratch folder for the analysis.
  scratchDir: "${OPENCGA.ANALYSIS.SCRATCH.DIR}"
  # Default URL for downloading analysis resources.
  resourceUrl: "http://resources.opencb.org/opencb/opencga/analysis/resources/resources-${project.parent.version}.json"
  fetchResourcesOnInit: true
  # Docker used by OpenCGA analysis and containing external tools such as samtools, bcftools, tabix, fastqc, plink1.9, bwa and r-base
  # You can indicate the version, e.g: opencb/opencga-ext-tools:2.12.0, otherwise the current OpenCGA version will be used
  opencgaExtTools: "opencb/opencga-ext-tools"
  tools:
    - id: "exomiser"
      version: "13.1"
      dockerId: "exomiser/exomiser-cli:13.1.0"
      resources:
        HG19: "exomiser/2109_hg19"
        HG38: "exomiser/2109_hg38"
        PHENOTYPE: "2109_phenotype"
    - id: "exomiser"
      version: "14.0"
      defaultVersion: true
      dockerId: "exomiser/exomiser-cli:14.0.0"
      resources:
        HG19: "exomiser/2402_hg19"
        HG38: "exomiser/2402_hg38"
        PHENOTYPE: "2402_phenotype"
    - id: "mutational-signature"
      resources:
        GRCH38_FA: "reference-genomes/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz"
        GRCH38_FAI: "reference-genomes/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz.fai"
        GRCH38_GZI: "reference-genomes/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz.gzi"
        GRCH37_FA: "reference-genomes/Homo_sapiens.GRCh37.dna.primary_assembly.fa.gz"
        GRCH37_FAI: "reference-genomes/Homo_sapiens.GRCh37.dna.primary_assembly.fa.gz.fai"
        GRCH37_GZI: "reference-genomes/Homo_sapiens.GRCh37.dna.primary_assembly.fa.gz.gzi"
  execution:
    # Accepted values are "local", "SGE", "azure-batch", "k8s"
    # see org.opencb.opencga.master.monitor.executors.ExecutorFactory
    id: "${OPENCGA.EXECUTION.MODE}"
    defaultQueue: ""            # Default queue to be used to submit jobs
    availableQueues:            # Other queues for specific applications
    toolsPerQueue:
    #       docker:
    #          - "circos"
    #          - "deeptools"
    #          - "bwa"
    #          - "fastqc"
    #          - "gatk"
    #          - "picard"
    #          - "plink"
    #          - "rvtests"
    #          - "samtools"
    #          - "relatedness"
    #          - "family-qc"
    #          - "sample-qc"
    #          - "individual-qc"
    #          - "mutational-signature"
    #       fast:
    #          - "alignmentIndex"
    #       slow:
    #          - "coverage"
    #          - "alignmentStats"
    maxConcurrentJobs:
      variant-index: 20
      variant-annotation-index: 5
      variant-secondary-annotation-index: 2
      variant-secondary-sample-index: 2
    options:
      ## Job reuse policy. Do not create a new job if an equivalent PENDING or QUEUED job exists.
      jobs.reuse.enabled: true
      ## List of tools to apply the reuse policy. Add `.*` to apply widely.
      jobs.reuse.tools:
        - "variant-index"
        - "variant-stats-index"
        - "variant-annotation-index"
        - "variant-secondary-annotation-index"
        - "variant-secondary-sample-index"
      ## Local executor configuration
      local.maxConcurrentJobs: 2    # Max number of concurrent jobs to be executed locally in the master
      ## Azure Batch Service configuration example
      # azure.batchAccount : "batchAccount"
      # azure.batchKey : "batchKey"
      # azure.batchUri : "https://batchservice.uksouth.batch.azure.com"
      # azure.batchPoolId : "poolId"
      # azure.dockerImageName : "openCGADockerImageName"
      # azure.dockerArgs : "dockerRunOptions"

      ## Kubernetes executor configuration example
      # k8s.masterUrl: "https://192.168.99.100:8443/"
      k8s.clientTimeout: 30000 # ms
      k8s.terminationGracePeriodSeconds: 300 # s
      k8s.logToStdout: true
      k8s.imageName: "opencb/opencga-base:${project.parent.version}-hdp3.1"
      k8s.imagePullPolicy: "IfNotPresent"
      #      k8s.imagePullSecrets:
      #        name : "dockerhub-secrets-name"
      k8s.ttlSecondsAfterFinished: 3600 # s
      k8s.namespace: "default"
      # FOR Cluster Autoscaler and dedicated jobs agent pool:
      k8s.requests:
        cpu: 3
        memory: "12G"
      k8s.limits:
        cpu: 4
        memory: "13G"
      # Job java heap. If undefined, will use "requests.memory - 300MiB"
      k8s.javaHeap: "11700M"
#      k8s.envs:
#        KEY: value
      k8s.nodeSelector:
        agentpool: jobs
        kubernetes.io/os: linux
        kubernetes.io/role: agent
      # FOR ACI:
      # k8s.requests:
      #   cpu: 2
      #   memory: "12G"
      # k8s.limits:
      #   cpu: 2
      #   memory: "12G"
      # k8s.nodeSelector:
      #   kubernetes.io/role: agent
      #   kubernetes.io/os: linux
      #   type: virtual-kubelet
      # k8s.tolerations:
      # - key: virtual-kubelet.io/provider
      #   operator: Exists
      # - key: azure.com/aci
      #   effect: NoSchedule

      k8s.volumeMounts:
        - name: conf
          mountPath: /opt/opencga/conf
        - name: sessions
          mountPath: /opt/opencga/sessions
        - name: variants
          mountPath: /opt/opencga/variants
        - name: analysisconf
          mountPath: /opt/opencga/analysis
      k8s.volumes:
        - name: conf
          persistentVolumeClaim:
            claimName: "pvc-opencga-conf"
        - name: sessions
          persistentVolumeClaim:
            claimName: "pvc-opencga-sessions"
        - name: variants
          persistentVolumeClaim:
            claimName: "pvc-opencga-variants"
        - name: analysisconf
          persistentVolumeClaim:
            claimName: "pvc-opencga-analysisconf"
      k8s.podSecurityContext:
        runAsNonRoot: true
      k8s.securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        readOnlyRootFilesystem: false

  # List of analysis frameworks
  frameworks:
    - id: "local"
      available: true
      options: { }

    - id: "spark"
      available: false
      queue: "hadoop_queue" # Special executor queue to be used for jobs using this framework.
      options: # Spark properties from https://spark.apache.org/docs/latest/configuration.html#viewing-spark-properties
        spark.executor.memory: "1g"

    - id: "mapreduce"
      available: false
      queue: "hadoop_queue" # Special executor queue to be used for jobs using this framework. This is NOT a yarn queue.
      options: # MapReduce configuration from https://hadoop.apache.org/docs/r2.7.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
        mapreduce.job.queuename: default

email:
  host: ${OPENCGA.MAIL.HOST}
  port: ${OPENCGA.MAIL.PORT}
  user: ${OPENCGA.MAIL.USER}
  password: ${OPENCGA.MAIL.PASSWORD}
  from: ${OPENCGA.MAIL.USER}
  ssl: false

#hooks:
#  user@project:study:              # Full Qualified Name of the study.
#    file:                          # Entity where the hook will be checked
#     - field: "name"               # Field of the entity to be checked
#       value: "~(.*)SV.vcf.gz$"    # Value that needs to be satisfied to perform the hook action
#       stage: "CREATE"             # Stage when the hook will be checked
#       action: "ADD"               # Action to be performed
#       where: "tags"               # Field over which the action will be performed
#       what: "SV"                  # Value to be updated
